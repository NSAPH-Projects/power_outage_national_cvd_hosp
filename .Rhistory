total_cust_coverage_w_exclusion / total_customers_from_eia)
total_customers %>% knitr::kable()
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
# Identify power outage events, defining power outage based on a percentile
# cutoff of customers out. This is a denominator-independent exposure metric.
# Author: Heather
# Created: sometime in 2022
# Last updated: Oct 7th, 2024
# Libraries ---------------------------------------------------------------
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
source(here("code", 'functions', 'helpers_days_exposed_unexposed.R'))
# Read --------------------------------------------------------------------
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
counties <-
counties[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_out_hourly = customers_out_hourly_locf,
customers_served_total = downscaled_county_estimate
)]
View(counties)
glimpse(counties)
# get 99th percentile of customers_out by county.
counties[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
View(counties[1:1000,])
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/functions/helpers_percentile_based_outages.R")
# Identify power outage events, defining power outage based on a percentile
# cutoff of customers out. This is a denominator-independent exposure metric.
# Author: Heather
# Created: sometime in 2022
# Last updated: Oct 7th, 2024
# Libraries ---------------------------------------------------------------
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
source(here("code", 'functions', 'helpers_percentile_based_outages.R'))
# Read --------------------------------------------------------------------
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
counties <-
counties[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_out_hourly = customers_out_hourly_locf,
customers_served_total = downscaled_county_estimate
)]
# get 99th percentile of customers_out by county.
counties[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
# Do ----------------------------------------------------------------------
exposures_99_9 <-
get_exposure_on_percentile(counties, outage_duration = hours(8))
View(exposures_99_9)
# Identify power outage events, defining power outage based on a percentile
# cutoff of customers out. This is a denominator-independent exposure metric.
# Author: Heather
# Created: sometime in 2022
# Last updated: Oct 7th, 2024
# Libraries ---------------------------------------------------------------
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
source(here("code", 'functions', 'helpers_percentile_based_outages.R'))
# Read --------------------------------------------------------------------
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
counties <-
counties[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_out_hourly = customers_out_hourly_locf,
customers_served_total = downscaled_county_estimate
)]
# get 99th percentile of customers_out by county.
counties[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
# Do ----------------------------------------------------------------------
exposures_99_9_1_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(1))
exposures_99_9_2_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(1))
exposures_99_9_3_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(1))
View(exposures_99_9_1_hr)
exposures_99_9_2_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(2))
exposures_99_9_3_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(4))
id_percentile <- counties[customers_out_hourly != 0]
id_percentile[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
id_percentile <- counties[customers_out_hourly != 0]
id_percentile[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
id_percentile <- select(five_digit_fips, year, cut_point) %>% distinct()
colnames(id_percentile)
id_percentile <- counties[customers_out_hourly != 0]
id_percentile[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
colnames(id_percentile)
id_percentile <- id_percentile %>% select(five_digit_fips, year, cut_point) %>% distinct()
View(id_percentile)
# Identify power outage events, defining power outage based on a percentile
# cutoff of customers out. This is a denominator-independent exposure metric.
# Author: Heather
# Created: sometime in 2022
# Last updated: Oct 7th, 2024
# Libraries ---------------------------------------------------------------
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
source(here("code", 'functions', 'helpers_percentile_based_outages.R'))
# Read --------------------------------------------------------------------
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
counties <-
counties[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_out_hourly = customers_out_hourly_locf,
customers_served_total = downscaled_county_estimate
)]
id_percentile <- counties[customers_out_hourly != 0]
id_percentile[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
id_percentile <-
id_percentile %>%
select(five_digit_fips, year, cut_point) %>%
distinct()
# get 99th percentile of customers_out by county.
counties <- counties %>% left_join(id_percentile)
exposures_99_9_1_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(1))
exposures_99_9_2_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(2))
exposures_99_9_3_hr <-
get_exposure_on_percentile(counties, outage_duration = hours(4))
View(exposures_99_9_1_hr)
# Identify power outage events, defining power outage based on a percentile
# cutoff of customers out. This is a denominator-independent exposure metric.
# Author: Heather
# Created: sometime in 2022
# Last updated: Oct 7th, 2024
# Libraries ---------------------------------------------------------------
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
source(here("code", 'functions', 'helpers_percentile_based_outages.R'))
# Read --------------------------------------------------------------------
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
counties <-
counties[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_out_hourly = customers_out_hourly_locf,
customers_served_total = downscaled_county_estimate
)]
id_percentile[, cut_point := quantile(customers_out_hourly, 0.999),
by = .(clean_state_name, clean_county_name, five_digit_fips, year)]
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/b06_identify_outages_percentile.R")
View(exposures_99_9_1_hr)
View(exposures_99_9_1_hr)
View(exposures_99_9_2_hr)
View(exposures_99_9_3_hr)
colnames(exposures_99_9_1_hr)
combined_df <- Reduce(function(x, y)
merge(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
all_exposures <- list(exposures_99_9_1_hr,
exposures_99_9_2_hr,
exposures_99_9_4_hr)
exposures_99_9_4_hr <- exposures_99_9_3_hr
all_exposures <- list(exposures_99_9_1_hr,
exposures_99_9_2_hr,
exposures_99_9_4_hr)
combined_df <- Reduce(function(x, y)
merge(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
View(combined_df)
write_fst(
combined_df,
here(
"data",
"power_outage_exposure_data_cleaning_output",
"days_exposed_unexposed_percentile_based_exposure.fst"
)
)
renv::snapshot()
percentile_based_exposure <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"days_exposed_unexposed_percentile_based_exposure.fst"
)
)
pacman::p_load(tidyverse, data.table, fst)
percentile_based_exposure <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"days_exposed_unexposed_percentile_based_exposure.fst"
)
)
pacman::p_load(here, tidyverse, data.table, fst)
percentile_based_exposure <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"days_exposed_unexposed_percentile_based_exposure.fst"
)
)
binary_exposure <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"all_days_exposed_unexposed.fst"
)
)
daily_hrs_out <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"daily_hrs_out.fst"
)
)
View(binary_exposure)
View(daily_hrs_out)
View(percentile_based_exposure)
colnames(percentile_based_exposure)
colanmes(daily_hrs_out)
colnames(daily_hrs_out)
colnames(binary_exposure)
all_exposures <- percentile_based_exposure %>%
left_join(daily_hrs_out) %>%
left_join(binary_exposure)
View(all_exposures)
colnames(all_exposures)
skimr::skim(all_exposures)
install.packages(skimr)
renv::install('skimr')
renv::snapshot()
skimr::skim(all_exposures)
length(unique(all_exposures$five_digit_fips))
# Create analytic data
pacman::p_load(here, tidyverse, data.table, fst)
# Read --------------------------------------------------------------------
percentile_based_exposure <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"days_exposed_unexposed_percentile_based_exposure.fst"
)
)
binary_exposure <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"all_days_exposed_unexposed.fst"
)
)
daily_hrs_out <- read_fst(
here(
'data',
"power_outage_exposure_data_cleaning_output",
"daily_hrs_out.fst"
)
)
all_exposures <- percentile_based_exposure %>%
left_join(daily_hrs_out) %>%
left_join(binary_exposure)
all_exposures <-
all_exposures %>%
mutate(year = lubridate::year(day)) %>%
filter(year == 2018)
write_csv(
all_exposures,
here(
'data',
"power_outage_exposure_data_cleaning_output",
"analytic_exposure_data_2018.csv"
)
)
write_fst(
all_exposures,
here(
'data',
"power_outage_exposure_data_cleaning_output",
"analytic_exposure_data_2018.fst"
)
)
pacman::p_load(here, tidyverse, data.table, fst, arrow)
write_parquet(
all_exposures,
here(
'data',
"power_outage_exposure_data_cleaning_output",
"analytic_exposure_data_2018.parquet"
)
)
renv::remove(MASS)
renv::remove('MASS')
renv::snapshot()
renv::update()
pacman::p_load(arrow, tidyverse, here, sf, ggthemes, arrow)
meteo_vars <- read_parquet(here('data', 'meteo_vars.parquet'))
county_backbone <- read_rds(here("data", "cotus_county_shp_w_fips.RDS"))
us_counties <- readRDS(here("data", "counties_sf.RDS")) %>%
rename(five_digit_fips = county_fips) %>%
filter(five_digit_fips %in% county_backbone$five_digit_fips)
meteo_vars <- meteo_vars %>%
group_by(five_digit_fips) %>%
summarize(
mean_min_temp = mean(min_temp),
mean_max_temp = mean(max_temp),
max_precip = max(precip),
max_wind = max(wind_speed)
)
county_backbone <- county_backbone %>% left_join(meteo_vars)
p1 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_min_temp, color = NA)) +
scale_fill_viridis_c(name = "Mean minimum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean minimum temp'))
ggsave(p1, here('figures', 'figures_output', 'plot_min_temp.png'))
ggsave(plot = p1, here('figures', 'figures_output', 'plot_min_temp.png'))
p1 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_min_temp), color = NA) +
scale_fill_viridis_c(name = "Mean minimum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean minimum temp'))
ggsave(plot = p1, here('figures', 'figures_output', 'plot_min_temp.png'))
pdf(here("figures", "figures_output", "weather_vars.pdf"))
p1 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_min_temp), color = NA) +
scale_fill_viridis_c(name = "Mean minimum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean minimum temp'))
print(p1)
p2 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_max_temp, color = NA)) +
scale_fill_viridis_c(name = "Mean maximum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean maximum temp'))
print(p2)
p3 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = max_precip, color = NA)) +
scale_fill_viridis_c(name = "Maximum daily precipitation gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max precip'))
print(p3)
p3 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = max_precip, color = NA)) +
scale_fill_viridis_c(name = "Maximum wind speed gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max wind speed'))
print(p4)
p4 <- county_backbone |>
geom_sf(aes(fill = max_precip) +
theme_map() +
p4 <- county_backbone |>
)
p4 <- county_backbone |>
p4 <- county_backbone %>%
)
p4 <- county_backbone %>%
)
p4 <- county_backbone %>%
ggplot() +
geom_sf(aes(fill = max_precip) +
scale_fill_viridis_c(name = "Maximum wind speed gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max wind speed'))
p4 <- county_backbone %>%
p4 <- county_backbone %>%
ggplot() +
geom_sf(aes(fill = max_precip)) +
scale_fill_viridis_c(name = "Maximum wind speed gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max wind speed'))
print(p4)
dev.off()
# Plot gridmet data already cleaned by NSAPH
# Libraries ---------------------------------------------------------------
pacman::p_load(arrow, tidyverse, here, sf, ggthemes, arrow)
# Read --------------------------------------------------------------------
meteo_vars <- read_parquet(here('data', 'meteo_vars.parquet'))
county_backbone <- read_rds(here("data", "cotus_county_shp_w_fips.RDS"))
us_counties <- readRDS(here("data", "counties_sf.RDS")) %>%
rename(five_digit_fips = county_fips) %>%
filter(five_digit_fips %in% county_backbone$five_digit_fips)
pacman::p_load(arrow, tidyverse, here, sf, ggthemes, arrow)
meteo_vars <- read_parquet(here('data', 'meteo_vars.parquet'))
county_backbone <- read_rds(here("data", "cotus_county_shp_w_fips.RDS"))
meteo_vars <- meteo_vars %>%
group_by(five_digit_fips) %>%
summarize(
mean_min_temp = mean(min_temp),
mean_max_temp = mean(max_temp),
max_precip = max(precip),
max_wind = max(wind_speed)
)
county_backbone <- county_backbone %>% left_join(meteo_vars)
pdf(here("figures", "figures_output", "weather_vars.pdf"))
p1 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_min_temp), color = NA) +
scale_fill_viridis_c(name = "Mean minimum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean minimum temp'))
print(p1)
p2 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_max_temp)) +
scale_fill_viridis_c(name = "Mean maximum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean maximum temp'))
print(p2)
p3 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = max_precip)) +
scale_fill_viridis_c(name = "Maximum daily precipitation gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max precip'))
print(p3)
p4 <- county_backbone %>%
ggplot() +
geom_sf(aes(fill = max_precip)) +
scale_fill_viridis_c(name = "Maximum wind speed gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max wind speed'))
print(p4)
dev.off()
# Plot gridmet data already cleaned by NSAPH
# Libraries ---------------------------------------------------------------
pacman::p_load(arrow, tidyverse, here, sf, ggthemes, arrow)
# Read --------------------------------------------------------------------
meteo_vars <- read_parquet(here('data', 'meteo_vars.parquet'))
county_backbone <- read_rds(here("data", "cotus_county_shp_w_fips.RDS"))
# Plot real quick ---------------------------------------------------------
meteo_vars <- meteo_vars %>%
group_by(five_digit_fips) %>%
summarize(
mean_min_temp = mean(min_temp),
mean_max_temp = mean(max_temp),
max_precip = max(precip),
max_wind = max(wind_speed)
)
county_backbone <- county_backbone %>% left_join(meteo_vars)
pdf(here("figures", "figures_output", "weather_vars.pdf"))
p1 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_min_temp), color = NA) +
scale_fill_viridis_c(name = "Mean minimum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean minimum temp'))
#ggsave(plot = p1, here('figures', 'figures_output', 'plot_min_temp.png'))
print(p1)
p2 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = mean_max_temp), color = NA) +
scale_fill_viridis_c(name = "Mean maximum temperature gridmet for 2018") +
theme_map() +
ggtitle(paste0('Mean maximum temp'))
print(p2)
p3 <- county_backbone |>
ggplot() +
geom_sf(aes(fill = max_precip), color = NA) +
scale_fill_viridis_c(name = "Maximum daily precipitation gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max precip'))
print(p3)
p4 <- county_backbone %>%
ggplot() +
geom_sf(aes(fill = max_precip), color = NA) +
scale_fill_viridis_c(name = "Maximum wind speed gridmet for 2018") +
theme_map() +
ggtitle(paste0('Max wind speed'))
print(p4)
dev.off()
