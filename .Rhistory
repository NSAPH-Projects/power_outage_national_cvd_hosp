"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
counties <-
counties[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_out_hourly = customers_out_hourly_locf,
customers_served_total = customers_served_estimate_to_use
)]
# Get exposures -----------------------------------------------------------
# call the get_exposure function from helpers, on all cut points and durations
# of interest.
cut_points <- c(0.005, 0.01, 0.03, 0.05)
exposure_8_hrs <- lapply(cut_points, function(cut_point) {
get_exposure(counties, cut_point, outage_duration = hours(8))  # Example outage_duration
})
exposure_12_hrs <- lapply(cut_points, function(cut_point) {
get_exposure(counties, cut_point, outage_duration = hours(12))  # Example outage_duration
})
exposure_4_hrs <- lapply(cut_points, function(cut_point) {
get_exposure(counties, cut_point, outage_duration = hours(4))  # Example outage_duration
})
all_exposures <- list(exposure_8_hrs, exposure_4_hrs, exposure_12_hrs)
combined_df <- Reduce(function(x, y)
merge(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
saveRDS(
combined_df,
here(
"data",
"power_outage_exposure_data_cleaning_output",
"all_days_exposed_unexposed.RDS"
)
)
View(combined_df)
?merge
combined_df <- combined_df %>% select(
clean_state_name,
clean_county_name,
five_digit_fips,
exposed_8_hrs_0.005,
exposed_8_hrs_0.01,
exposed_8_hrs_0.03,
exposed_8_hrs_0.05,
exposed_4_hrs_0.005,
exposed_4_hrs_0.01,
exposed_8_hrs_0.03,
exposed_4_hrs_0.05,
exposed_1_hrs_0.005,
exposed_1_hrs_0.01,
exposed_1_hrs_0.03,
exposed_8_hrs_0.05
)
saveRDS(
combined_df,
here(
"data",
"power_outage_exposure_data_cleaning_output",
"all_days_exposed_unexposed.RDS"
)
)
dim(exposure_4_hrs[[1]])
dim(combiend_df)
dim(combined_df)
grep("^exposed", names(result), value = TRUE)
grep("^exposed", names(combined_df), value = TRUE)
combined_df <- Reduce(function(x, y)
merge(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
combined_df <- combined_df %>% select(
c('clean_state_name',
'clean_county_name',
'five_digit_fips',
exposure_cols)
exposed_8_hrs_0.005,
combined_df <- combined_df %>% select(
c('clean_state_name',
'clean_county_name',
'five_digit_fips',
exposure_cols))
combined_df <- combined_df %>% select(
c('clean_state_name',
'clean_county_name',
'five_digit_fips',
exposure_cols))
exposure_cols <- grep("^exposed", names(combined_df), value = TRUE)
combined_df <- combined_df %>% select(
c('clean_state_name',
'clean_county_name',
'five_digit_fips',
exposure_cols))
combined_df <- combined_df %>% select(
clean_state_name,
clean_county_name,
five_digit_fips,
all_of(exposure_cols))
dim(combined_df)
View(combined_df)
all_exposures <- list(exposure_8_hrs, exposure_4_hrs, exposure_12_hrs)
combined_df <- Reduce(function(x, y)
data.table::merge(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
?merge
library(data.table)
combined_df <- Reduce(function(x, y)
data.table::merge.data.table(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
combined_df <- Reduce(function(x, y)
data.table::merge.data.table(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
all_exposures <- list(exposure_8_hrs, exposure_4_hrs, exposure_12_hrs)
combined_df <- Reduce(function(x, y)
data.table::merge.data.table(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
colnames(exposure_12_hrs[[1]])
?Reduce
combined_df <- Reduce(function(x, y)
merge(x, y, by = c(
"clean_state_name", "clean_county_name", 'five_digit_fips', "day"
)), all_exposures)
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/draft_test_play.R")
write_fst(
combined_df,
here(
"data",
"power_outage_exposure_data_cleaning_output",
"all_days_exposed_unexposed.fst"
)
)
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
View(counties[1:1000,])
View(counties %>% filter(five_digit_fips == '06075]'))
View(counties %>% filter(five_digit_fips == '06075'))
pacman::p_load(tidyverse, here, lubridate, zoo, data.table, fst)
my.max <- function(x)
ifelse(!all(is.na(x)), max(x, na.rm = T), NA)
person_coverage_threshold <- 0.5
# read in EIA estimates downscaled to the county level in an earlier script
eia_estimates <-
read_rds(
here(
"data",
"power_outage_exposure_data_cleaning_output",
"downscaled_county_customer_estimates.RDS"
)
) %>%
select(year, five_digit_fips, downscaled_county_estimate)
# read in counties hourly data
counties <-
list.files(
here(
"data",
"power_outage_exposure_data_cleaning_output",
"hourly_county"
),
pattern = "*.fst",
full.names = TRUE
)
hourly <- lapply(counties, read_fst)
hourly <- rbindlist(hourly)
# reduce to just customer estimates
pous_based_estimates <- hourly %>%
select(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
customers_served_hourly,
county_person_time_missing
) %>% distinct()
pous_based_estimates <- pous_based_estimates %>% left_join(eia_estimates)
# mark when the pous data looks like it has an error
pous_based_estimates <- pous_based_estimates %>%
mutate(
too_big = case_when(
customers_served_hourly > downscaled_county_estimate ~ customers_served_hourly /
downscaled_county_estimate,
T ~ 0
)
)
# select the appropriate columns
pous_based_estimates <- pous_based_estimates[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_served_hourly,
county_person_time_missing,
downscaled_county_estimate,
too_big
)]
# going to use the POUS estimates when they are less than twice the eia estimate
pous_based_estimates <- pous_based_estimates %>%
mutate(
customers_served_estimate_to_use = case_when(
too_big < 2 ~ customers_served_hourly,
T ~ downscaled_county_estimate
)
)
# exclude low person coverage - should update this to be person-time coverage,
# and as an indicator; first collect cols
estimate_missing <-
pous_based_estimates %>%
select(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
customers_served_hourly,
county_person_time_missing,
downscaled_county_estimate,
customers_served_estimate_to_use
) %>%
distinct()
# do calc
estimate_missing <-
estimate_missing %>%
mutate(
expected_hrs = downscaled_county_estimate * 365 * 24,
# hrs that should be in the dataset
hrs_served = customers_served_estimate_to_use * 365 * 24,
# person-hrs that should be in the dataset
hrs_actually_served = hrs_served - (county_person_time_missing /
6),
# subtract missing hrs
p_present = hrs_actually_served / expected_hrs
) # percentage served out of total hrs
hourly <- hourly %>% left_join(estimate_missing)
colnames(hourly)
pacman::p_load(tidyverse, here, lubridate, data.table, fst)
counties <-
read_fst(here("data",
"power_outage_exposure_data_cleaning_output",
"hourly_data_with_coverage_exclusions.fst")) |>
as.data.table()
colnames(counties)
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b04_id_outages_continuous_measures.R")
source(here('code', 'functions', 'exposure_data_cleaning_helpers.R'))
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b04_id_outages_continuous_measures.R")
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b05_identify_daily_binary_exposure.R")
# Expand Out Power Outages
# This script expands power outage data into a time series, from its raw
# form where the dataset only includes entries for changes in customers_out
# (see the POUS documentation for an explanation of how the raw data is
# structured). It does this one county at a time, and saves each expanded county
# in the 'hourly county' folder in the 'data' folder.
# Last updated: Oct 3rd, 2024
# Author: Heather
# Libraries ---------------------------------------------------------------
# i pacmaned in all these scripts for u lauren
pacman::p_load(tidyverse, zoo, here, lubridate, data.table, fst)
source(here("code", "functions", "exposure_data_cleaning_helpers_oct_9.R"))
# Constants ---------------------------------------------------------------
# just to make sure we make the same chunks each time
set.seed(7)
# we will make a version of the time series with customers out counts that
# have last obs carried forward, but we will impute a maximum of 4 hours
hour_thrshld <- dhours(4)
max_nas_to_impute <- hour_thrshld / dminutes(x = 5)
# fastest to do all years at once, taking advantage of data.table's
# infrastructure - excluding 2017 though bc it's garbage
#intervals_2017 <- generate_intervals(2017)
intervals_2018 <- generate_intervals(2018)
intervals_2019 <- generate_intervals(2019)
intervals_2020 <- generate_intervals(2020)
intervals_dt <-
data.table(date = c(
#intervals_2017,
intervals_2018,
intervals_2019,
intervals_2020
))
# read in raw data with cleaned names
pous_data <-
read_fst(
here(
"data",
"power_outage_exposure_data_cleaning_output",
"raw_with_fips.fst"
)
) |>
as.data.table()
pous_list <- sort(unique(pous_data$five_digit_fips))
pous_l_split <- split(pous_list, ceiling(seq_along(pous_list) / 15))
i = 1
# get chunk to process
pous_dat_chunk <-
get_chunk(raw_pous_data = pous_data, chunk_list = pous_l_split,
list_position = i)
# get city-utility id frame
city_utilities <- get_unique_city_utilities(pous_dat_chunk = pous_dat_chunk)
# get ten min time series
# intervals <-
#   data.table(date = generate_intervals(year))
ten_min_time_series <-
create_ten_min_series(id_frame = city_utilities,
intervals_dt = intervals_dt)
# id missing observations
pous_dat_chunk <-
id_missing_obs(pous_dat_chunk = pous_dat_chunk)
# expand the data to ten min intervals
pous_dat_chunk <-
expand_to_10_min_intervals(pous_dat_chunk = pous_dat_chunk)
# replace -99 missing data indicators with NAs
pous_dat_chunk <- add_NAs_to_chunk(pous_dat_chunk = pous_dat_chunk)
# expand to a full year
pous_dat_chunk <-
expand_to_full_year(pous_dat_chunk = pous_dat_chunk,
city_utility_time_series = ten_min_time_series,
city_utilities = city_utilities)
# add an additional time series with locf to the data
pous_dat_chunk <-
add_locf_to_chunk(pous_dat_chunk = pous_dat_chunk,
max_nas_to_impute = max_nas_to_impute)
# add customer served estimates by city_utility to chunk
pous_dat_chunk <- calculate_customer_served_est(pous_dat_chunk)
# calculate person-time missing by city-utility ID and add it to data
pous_dat_chunk <- add_person_time_missing(pous_dat_chunk,
city_utilities = city_utilities)
dim(pous_dat_chunk)
colnames(pous_dat_chunk)
ii <- pous_dat_chunk %>% select(city_utility_name_id, city_utility_customers_served_est, year) %>% distinct() %>% group_by(city_utility_name_id, year) %>% mutate(n = n())
View(ii)
# want instead to sum customers out to hour here
pous_dat_chunk <- aggregate_customers_out_to_hour(pous_dat_chunk)
ii <- pous_dat_chunk %>% select(city_utility_name_id, city_utility_customers_served_est, year) %>% distinct() %>% group_by(city_utility_name_id, year) %>% mutate(n = n())
View(ii)
dim(pous_dat_chunk)
# want to calculate person time missing at the hourly level here
pous_dat_chunk <- add_person_time_missing_hourly(pous_dat_chunk)
ii <- pous_dat_chunk %>% select(city_utility_name_id, county_person_time_missing_hours, year) %>% distinct() %>% group_by(city_utility_name_id, year) %>% mutate(n = n())
View(ii)
colnames(pous_dat_chunk)
sum_customers_out_to_county_hourly <- function(pous_dat_chunk) {
# sum customers without power to county level
pous_dat_chunk <- pous_dat_chunk[, .(
customers_out_hourly_locf = sum(customers_out_hourly_locf, na.rm = TRUE),
customers_out_hourly_no_locf = sum(customers_out_hourly_no_locf,
na.rm = TRUE),
customers_served_county = sum(city_utility_customers_served_est,
na.rm = TRUE)
), by = .(
clean_state_name,
clean_county_name,
five_digit_fips,
hour,
year,
county_person_time_missing_hours,
customers_served_hourly
)]
return(pous_dat_chunk)
}
# sum customers out to county
pous_dat_chunk <- sum_customers_out_to_county_hourly(pous_dat_chunk)
sum_customers_out_to_county_hourly <- function(pous_dat_chunk) {
# sum customers without power to county level
pous_dat_chunk <- pous_dat_chunk[, .(
customers_out_hourly_locf = sum(customers_out_hourly_locf, na.rm = TRUE),
customers_out_hourly_no_locf = sum(customers_out_hourly_no_locf,
na.rm = TRUE),
customers_served_county = sum(city_utility_customers_served_est,
na.rm = TRUE)
), by = .(
clean_state_name,
clean_county_name,
five_digit_fips,
hour,
year,
county_person_time_missing_hours
)]
return(pous_dat_chunk)
}
# sum customers out to county
pous_dat_chunk <- sum_customers_out_to_county_hourly(pous_dat_chunk)
ii <- pous_dat_chunk %>% select(five_digit_fips, year, customers_served_county) %>% distinct() %>% group_by(five_digit_fips, year) %>% mutate(n = n())
View(ii)
colnames(pous_dat_chunk)
sum(is.na(pous_dat_chunk$customers_out_hourly_locf))
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b02_expand_to_hourly_oct_9.R")
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/figures/plot_person_coverage.R")
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b04_id_outages_continuous_measures.R")
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b05_identify_daily_binary_exposure.R")
# Join customer estimates from EIA to the live customer estimate data,
# calculate person-coverage, and then eliminate counties with insufficient
# coverage.
# Author: Heather
# Last updated: Oct 4th, 2024
# Libraries ---------------------------------------------------------------
pacman::p_load(tidyverse, here, lubridate, zoo, data.table, fst)
my.max <- function(x)
ifelse(!all(is.na(x)), max(x, na.rm = T), NA)
person_coverage_threshold <- 0.5
# Do ----------------------------------------------------------------------
# read in EIA estimates downscaled to the county level in an earlier script
eia_estimates <-
read_rds(
here(
"data",
"power_outage_exposure_data_cleaning_output",
"downscaled_county_customer_estimates.RDS"
)
) %>%
select(year, five_digit_fips, downscaled_county_estimate)
# read in counties hourly data
counties <-
list.files(
here(
"data",
"power_outage_exposure_data_cleaning_output",
"hourly_county"
),
pattern = "*.fst",
full.names = TRUE
)
hourly <- lapply(counties, read_fst)
hourly <- rbindlist(hourly)
# reduce to just customer estimates
pous_based_estimates <- hourly %>%
select(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
customers_served_county,
county_person_time_missing_hours,
) %>% distinct()
# Do ----------------------------------------------------------------------
pous_based_estimates <- pous_based_estimates %>% left_join(eia_estimates)
# mark when the pous data looks like it has an error
pous_based_estimates <- pous_based_estimates %>%
mutate(
too_big = case_when(
customers_served_county > downscaled_county_estimate ~
customers_served_county /
downscaled_county_estimate,
T ~ 0
)
)
# select the appropriate columns
pous_based_estimates <- pous_based_estimates[, .(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
hour,
customers_served_county,
county_person_time_missing_hours,
downscaled_county_estimate,
too_big
)]
# going to use the POUS estimates when they are less than twice the eia estimate
pous_based_estimates <- pous_based_estimates %>%
mutate(
customers_served_estimate_to_use = case_when(
too_big < 2 ~ customers_served_county,
T ~ downscaled_county_estimate
)
)
# exclude low person coverage - should update this to be person-time coverage,
# and as an indicator; first collect cols
estimate_missing <-
pous_based_estimates %>%
select(
clean_state_name,
clean_county_name,
five_digit_fips,
year,
customers_served_county,
county_person_time_missing_hours,
downscaled_county_estimate,
customers_served_estimate_to_use
) %>%
distinct()
# do calc
estimate_missing <-
estimate_missing %>%
mutate(
expected_hrs = downscaled_county_estimate * 365 * 24,
# hrs that should be in the dataset
hrs_served = customers_served_estimate_to_use * 365 * 24,
# person-hrs that should be in the dataset
hrs_actually_served = hrs_served - (county_person_time_missing_hours),
# subtract missing hrs
p_present = hrs_actually_served / expected_hrs
) # percentage served out of total hrs
View(estimate_missing)
# also write a denom frame
estimate_missing <-
estimate_missing %>%
select(five_digit_fips,
year,
county_customers = downscaled_county_estimate,
percent_served = p_present)
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/code/data_prep/power_outage_exposure_data_prep/b03_attach_denoms.R")
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/figures/create_figures_scripts/plot_power_outage_exposure.R")
source("/Volumes/squirrel-utopia 2/power_outage_national_cvd_hosp/figures/create_figures_scripts/plot_total_hrs_without_power_2018.R")
